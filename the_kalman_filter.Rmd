---
title: "The Kalman Filter: An Applied Introduction"
author: "Matt Brigida"
output: html_document
runtime: shiny
---

Note, the apps in this document are pulling data and doing some substantial calculations, so it may take a solid 30 seconds or more for the charts to render.

## Is a Company's Market Risk Constant?

Every undergraduate Finance student learns the CAPM, and at some point ([similar to this presentation](https://micfm.shinyapps.io/The_CAPM/)) estimates a firm's market risk ($\beta$) with the following regression:

$R_{s,t} = \alpha + \beta R_{m,t} + e_t$

where $R_{s,t}$, and $R_{m,t}$, are the return on some stock, and the return on the market, at time $t$.

Often the interested student will ask if market risk is really constant as the above equation assumes.  We could investigate this by breaking up a long time period into smaller subintervals, and estimating the above equation for each subinterval.  This is a sensible first approach.


##  Interactive App

Input a ticker in the app on the following slide, and it will break the last 5 years into 30 day periods, estimate $\beta$ over each period, and plot the time series of $\beta$s.

-  The default shows Citigroup's (ticker 'C') $\beta$ coefficient over time.  It starts at about 1 in 2010, and increases to about 4 by 2011.  From 2012 onward it ranges from 1 to 2.5.  Clearly there is significant variation in Citigroup's market risk over time.




## 

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(quantmod)
library(dygraphs)

inputPanel(
    textInput("ticker", label = "Stock Ticker", value = "C")
    )

renderDygraph({
    ## valdate ticker ----
    validate(
        need(input$ticker != "", "Input a valid US stock ticker.")
    )
    market <- getSymbols("^GSPC", src = "yahoo", auto.assign = F)
    adjMarket <- Ad(market)
    marketRet <- Delt(adjMarket)[-1]

    stock <- getSymbols(input$ticker, src = "yahoo", auto.assign = F)
    adjStock <- Ad(stock)
    stockRet <- Delt(adjStock)[-1]

    data <- merge.xts(stockRet, marketRet, join = "inner")
    names(data) <- c("stock", "market")
    data.mat <- matrix(data, ncol = 2)

    n <- floor(dim(data.mat)[1]/30)
    a <- rep(0, n)
    b <- rep(0, n)
    for (i in 1:n) {
        g <- 30 * (i - 1)
        h <- 30 * i
        reg <- lm(data.mat[g:h, 1] ~ data.mat[g:h, 2])
        a[i] <- reg$coef[1]
        b[i] <- reg$coef[2]
    }

    id <- index(to.monthly(data))
    a.xts <- as.xts(a, order.by = id[(length(id) - length(a) + 1):length(id)])
    b.xts <- as.xts(b, order.by = id[(length(id) - length(a) + 1):length(id)])
    names(b.xts) <- "Beta"
    dygraph(b.xts)

})
```


## BDE 1975 Test

For a formal test of instability in estimated coefficients we would use the Brown, Durbin, and Evans (1975) test.  See [this code for an implementation in R](https://github.com/Matt-Brigida/BDE_75/blob/master/BDE_75_test.R) of the [Brown, Durbin, and Evans (1975)](https://scholar.google.com/scholar?hl=en&q=brown+durbin+evans+1975) test.



## A More Formal Approach

Instead of running a separate regression over short intervals (assuming the coefficient is constant over each interval), we can formally assume that the coefficient may vary.  We do so by writing the equation in [state space]() form.  We then construct the likelihood function using [prediction error decomposition]().  


### Time-Varying Beta


$R_{s,t} = \alpha_t + \beta_t R_{m,t} + e_t$

where:

$\alpha_t = \mu + \gamma \alpha_{t-1} + \eta_t$

$\beta_t = \nu + \xi \beta_{t-1} + \epsilon_t$

where $\mu$, $\gamma$, $\nu$, and $\xi$ are hyperparameters which can be estimated via maximum likelihood.  Note, many implementations of the Kalman Filter will assume the hyperparameters are already known, so when looking at a software implementation pay close attention to whether the hyperparameters are estimated.

I recommend using [Python's Statsmodels implementation](https://www.statsmodels.org/stable/generated/statsmodels.tsa.statespace.kalman_filter.KalmanFilter.html) which will estimate the hyperparameters.

I'll omit the math of the Kalman Filter.  My recommendation is estimate the model in Statsmodels, and learn the math later.


```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(highcharter)
textInput("symb", "Ticker", "C")
dateRangeInput("dates", "Date range", start = "2015-01-01", end = as.character(Sys.Date()))   
sliderInput("init", "Initial Beta Value", min = -5, max = 5, value = 1, step= 0.1)
sliderInput("init.sd", "Initial Standard Deviation of Beta", min = 0.01, max = 1, value = 0.05, step= 0.01)
#plotOutput("distPlot")
highchartOutput("distPlot")
```


```{r, context="server", echo=FALSE}
library(quantmod)
library(compiler)
library(xts)
library(tsbox)

#output$distPlot <- renderPlot({
output$distPlot <- renderHighchart({
    lik <- function(theta, market, stock){


    ## R and Q transformed below (squared) --- so R is the standard deviation
    R <- theta[1]
    Q <- theta[2]
    F <- theta[3]
    mu <- theta[4]

    sampleLength <- length(market)
    
    ## beta estimate conditional on information through t and t-1 respectively
    beta_tt <- rep(0, sampleLength)
    beta_tt_1 <- rep(0, sampleLength)
    ## prediction error
    eta <- rep(0, sampleLength)
    ## conditional variance of the prediction error
    f <- rep(0, sampleLength)
    ## variance of beta conditional on information through t
    Ptt <- rep(0, sampleLength)
    ## variance of beta conditional on information through t-1
    Ptt_1 <- rep(0, sampleLength)
        
    beta_tt[1] <- input$init
    Ptt[1] <- (input$init.sd)^2

    for(i in 2:sampleLength){
    ## Prediction
        beta_tt_1[i] <- mu + F*beta_tt[i-1]
        Ptt_1[i] <- F*Ptt[i-1]*F+Q^2
        eta[i] <- stock[i]-market[i]*beta_tt_1[i]
        f[i] <- market[i]*Ptt_1[i]*market[i]+R^2
    ## Updating
        beta_tt[i] <- beta_tt_1[i]+Ptt_1[i]*market[i]*(1/f[i])*eta[i]
        Ptt[i] <- Ptt_1[i]-Ptt_1[i]*market[i]*(1/f[i])*market[i]*Ptt_1[i]
    }

    logl <- -0.5*sum(log((((2*pi)^sampleLength)*abs(f))[-1]))-.5*sum(eta*eta*(1/f),na.rm=T)

    return(-logl)
}

lik <- cmpfun(lik)
#}}}
  
  dataInput <- reactive({
    getSymbols(input$symb, src = "yahoo", 
               from = input$dates[1],
               to = input$dates[2],
               auto.assign = FALSE)
  })
  
  market.p <- getSymbols("^GSPC", src = "yahoo", 
                       from = "1980-01-01",
                       to = Sys.Date(),
                       auto.assign = FALSE)
  
#  output$plot <- renderPlot({   
    data.s <- dataInput()
    
# calculate returns ----
stock <- Delt(Ad(to.monthly(data.s)), type='log')[-1]
market <- Delt(Ad(to.monthly(market.p)), type='log')[-1]
rets <- merge.xts(stock, market, join = "inner")
names(rets) <- c("stock", "market")
stock <- rets[,1]
market <- rets[,2]

## Kalman Filter Starts here ----

theta.start <- c(0.01,0.01, 0.1, 0.1)
max.lik.optim <- optim(theta.start, lik, market=market, stock=stock, hessian=FALSE)

## Run though filter to get betas

    sampleLength <- length(market)
    
R.hat <- max.lik.optim$par[1]
Q.hat <- max.lik.optim$par[2]
F.hat <- max.lik.optim$par[3]
mu.hat <- max.lik.optim$par[4]

beta_tt <- rep(0, sampleLength)
    beta_tt_1 <- rep(0, sampleLength)
    eta <- rep(0, sampleLength)
    f <- rep(0, sampleLength)
    Ptt <- rep(0, sampleLength)
    Ptt_1 <- rep(0, sampleLength)
        
    beta_tt[1] <- input$init
    Ptt[1] <- (input$init.sd)^2

    for(i in 2:sampleLength){
    ## Prediction
        beta_tt_1[i] <- mu.hat + F.hat*beta_tt[i-1]
        Ptt_1[i] <- F.hat*Ptt[i-1]*F.hat+Q.hat^2
        eta[i] <- stock[i]-market[i]*beta_tt_1[i]
        f[i] <- market[i]*Ptt_1[i]*market[i]+R.hat^2
    ## Updating
        beta_tt[i] <- beta_tt_1[i]+Ptt_1[i]*market[i]*(1/f[i])*eta[i]
        Ptt[i] <- Ptt_1[i]-Ptt_1[i]*market[i]*(1/f[i])*market[i]*Ptt_1[i]
    }
    logl <- -0.5*sum(log((((2*pi)^sampleLength)*abs(f))[-1]))-.5*sum(eta*eta*(1/f),na.rm=T)

### End Kalman Filtering Code ----
    
### standard deviation of beta conditional on information through t
    sdBeta <- sqrt(Ptt)
    sdBeta <- as.xts(Ptt, order.by = index(rets))
    
### Variance of the conditional forecast error ----
    Htt_1 <- 0
    for (i in 2:sampleLength){
        Htt_1[i] <- market[i-1] * Ptt_1[i] * market[i-1] + R.hat * R.hat
    }

    kalman_filtered_beta <- as.xts(beta_tt, order.by = index(rets))
    forecast_variance <- as.xts(Htt_1, order.by = index(rets))
     
    hc <- hchart(ts_ts(kalman_filtered_beta)) |>
      hc_add_theme(hc_theme_darkunica()) |>
      hc_title(text = "Time-Varying Beta")
    
    hc
    #chartSeries(kalman_filtered_beta, theme = "white")
    #chartSeries(kalman_filtered_beta, theme = "black")
    
 })

```

### Conditional Volatility

Not only does the Kalman Filter give us an estimate of a stock's time-varying beta, but it also gives us an estimate the of uncertainy of the beta.








##

<!-- app showing time varying beta from the K filter -->






<!-- next presentation:  show the time series of the distribution of beta calculated from the K filter -- see the density.txt file -->

## A Note on Model Form

In addition to non-constant market risk, the beta coefficient may vary also because of ommitted variables---other factors are known to affect the return on stock.

